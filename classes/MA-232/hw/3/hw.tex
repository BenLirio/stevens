\documentclass{article}
\usepackage{amsmath}
\begin{document}
\begin{titlepage}
	\vspace*{\stretch{1.0}}
		\begin{center}
		\Large\textbf{Ben Lirio}\\
		\vspace*{\stretch{.1}}
		\large{3/12/21} \\
		\vspace*{\stretch{.1}}
		\large\textit{I pledge my honor that I have abided by the Steven Honor System.}
		\end{center}
	\vspace*{\stretch{2.0}}
\end{titlepage}
\section{Problem}
Let $A$ be that matrix. If $A$ has a null space in $\textrm{R}^4$ that spans two dimensions, I know $A$ must 4 columns, two of which are free. An $m = 2, n = 4$ sized matrix will satisfy these conditions.

\[
\begin{bmatrix}
a_{11} & a_{12} & a_{13} & a_{14} \\
a_{21} & a_{22} & a_{23} & a_{24}
\end{bmatrix}
\]
I will first generate my two independent columns in the first two position using a $2x2$ identity matrix. I am allowd to do this becuase I know two columns are independent, and I will be able to generate specific null space vectors if I set my dependent columns to have the correct coeficients.
\[
\begin{bmatrix}
1 & 0 & a_{13} & a_{14} \\
0 & 1 & a_{23} & a_{24}
\end{bmatrix}
\]
Let $u$ and $v$ represent each null space vector. After multiplying $Au = 0$ and $Av = 0$, I get the following relations.

$2 + a_{13} = 0$

$2 + a_{23} = 0$

$3 + a_{14} = 0$

$1 + a_{24} = 0$

I notice that all the variables are independent in the equations above, this means I will not have to do any substitution and can just skip to filling in the correct values for each $a_{ij}$

$a_{13} = -2$

$a_{23} = -2$

$a_{14} = -4$

$a_{24} = -1$

\[
A = 
\begin{bmatrix}
1 & 0 & -2 & -4 \\
0 & 1 & -2 & -1
\end{bmatrix}
\]
\section{Problem}
Let matrix $A$ be the one I am constructing. For the first two vectors I can just add them as columns in my matrix.
\[
\begin{bmatrix}
1 & 0 \\
1 & 3 \\
5 & 1  
\end{bmatrix}
\]
Next, becuase the null space is in $\textrm{R}^{3}$ I will add an additional column.
\[
\begin{bmatrix}
1 & 0 & a_{13} \\
1 & 3 & a_{23} \\
5 & 1 & a_{33} 
\end{bmatrix}
\]
Now I will multiply $A$ by the null space.

\[
\begin{bmatrix}
1 & 0 & a_{13} \\
1 & 3 & a_{23} \\
5 & 1 & a_{33} 
\end{bmatrix}
\cdot
\begin{bmatrix}
1 \\
1 \\
2 
\end{bmatrix}
=
\begin{bmatrix}
0 \\
0 \\
0 
\end{bmatrix}
\]
Which gives me the following equations.

$1 + 2a_{13} = 0$

$1 + 3 + 2a_{23} = 0$

$5 + 1 + 2a_{33} = 0$

Simplifying I get

$a_{13} = -\frac{1}{2}$

$a_{23} = -2$

$a_{33} = -3$

Now I can substitute these values back into my matrix
\[
\begin{bmatrix}
1 & 0 & -\frac{1}{2} \\
1 & 3 & -2 \\
5 & 1 & -3 
\end{bmatrix}
\]
\section{Problem}
I will be using the fact that a matrix which is invertable is indepent columns. By creating matrix $A$ such that the columns of $A$ are $u_{1}$ throuch $u_{3}$ I get.
\[
\begin{bmatrix}
1 & 1 & 1 \\
0 & 1 & 1 \\
0 & 0 & 1 \\
\end{bmatrix}
\]
I notice that simply subtracting $R2$ from $R1$ and subtracting $R3$ from $R2$, I get the identity matrix. And since row subtraction can be represented with a matrix $E$ I know that this matrix is invertable and therefore has independent columns.
Now to determine if $u_{1}$, $u_{2}$, $u_{3}$, $u_{4}$ is invertable, I will construct another matrix.
\[
\begin{bmatrix}
1 & 1 & 1 & 2 \\
0 & 1 & 1 & 3 \\
0 & 0 & 1 & 4 \\
\end{bmatrix}
\]
Using the fundamental theorem of linear algebra, I know $C(A) + N(A) = n$ where $n$ is the number of columns of this matrix. I also know that $C(A) = C(A^{T})$ and becuase $C(A^{T}) \le n$, where $n$ is the number of rows, I can assume $C(A) \le 3$, when $n = 3$. Furthermore, I can show $N(A)$ must be at least $1$ in order for $C(A) + N(A) = 4$. Therefore there is at least one vector in the null space of this matrix. Which leads me to the conclusion that while the previous matrix was independent, adding $u_{4}$ made them dependent. Also $u_{4} = 4u_{3} - u_{2} - u_{1}$.

\section{Problem}
The number of pivots of a matrix after elimination is equivalent to the rank. So I will put $A$ into the form of $U$ and count the number of pivots. If they equal $2$ then $A$ will have rank 2.

\[
\begin{bmatrix}
1 & 2 & 5 & 0 & 5 \\
0 & 0 & c & 2 & 2 \\
0 & 0 & 0 & d & 2 \\
\end{bmatrix}
\]
Currently I have 3 pivots $1, c, d$, but I will be able to use the fact that a value of $0$ can never be used as a pivot. So I will set $c = 0$.
\[
\begin{bmatrix}
1 & 2 & 5 & 0 & 5 \\
0 & 0 & 0 & 2 & 2 \\
0 & 0 & 0 & d & 2 \\
\end{bmatrix}
\]
Finnaly if I set $d = 2$, I will be able to get rid of the unwanted pivot by subtracting $R2$ from $R3$.
\[
U =
\begin{bmatrix}
1 & 2 & 5 & 0 & 5 \\
0 & 0 & 0 & 2 & 2 \\
0 & 0 & 0 & 0 & 0 \\
\end{bmatrix}
\]
Position $U_{11}$ and $U_{42}$ are the only valid positions for my pivots. So $U$ has two pivots, and as stated above, confirms that $A$ has rank 2.
\section{Problem}
A basis is a set of a subspace. One basis for $C(A)$ is:
\[
Column Space
\begin{bmatrix}
1 \\
1 \\
0 \\
\end{bmatrix}
\begin{bmatrix}
3 \\
4 \\
1 \\
\end{bmatrix}
\]
I found this basis by scanning the columns from left to right and selecting non-trivial columns that were independent of any previous columns I selected.

Col 1 is trivial, Skip

Col 2 is non-trivial and not a linear combinations of previously choosen columns, Add

Col 3 is 2 times Col 2, Skip

Col 4 is non-trivial a not a linear combination of Col 2, Add

Col 5 Can be made from 2 of Col 4 and -1 of Col 2, Skip

For the null space, I have already found the free columns as shown above, which are, $Col 1, 3, 5$. I will use each one of these to generate a vetor in the null space. By setting $Ax = 0$.
\[
Null Space
\begin{bmatrix}
1 \\
0 \\
0 \\
0 \\
0 \\
\end{bmatrix}
\begin{bmatrix}
0 \\
-2 \\
1 \\
0 \\
0 \\
\end{bmatrix}
\begin{bmatrix}
0 \\
1 \\
0 \\
-2 \\
1 \\
\end{bmatrix}
\]

For the row space I will transpose the matrix and find the column space in the same manner as I did before.
\[
A^{T} = 
\begin{bmatrix}
0 & 0 & 0 \\
1 & 1 & 0 \\
2 & 2 & 0 \\
3 & 4 & 1 \\
4 & 6 & 2 \\
\end{bmatrix}
\]

Col 1 is non trivial. Add

Col 2 is non trial and is not a linear combination of Col 1. Add

Col 3 is Col 2 - Col 1. Skip

\[
Row Space
\begin{bmatrix}
0 \\
1 \\
2 \\
4 \\
6 \\
\end{bmatrix}
\begin{bmatrix}
0 \\
1 \\
2 \\
3 \\
4 \\
\end{bmatrix}
\]
And finnaly for the Left Null space I will set $A^{T}x = 0$. Setting the free column of $A{T}$ to 1.
\[
Left Null Space
\begin{bmatrix}
1 \\
-1 \\
1 \\
\end{bmatrix}
\]
\section{Problem}
In order to find the two vectors that span the orthogonal complement $S^{\perp}$. I must satisfy the requirements of being a complement vector. Any orthogonal vector must have the property $s_1 \cdot v = 0$, and $s_2 \cdot v = 0$. This relation can be shown in matrix form like so
\[
\begin{bmatrix}
1 & 2 & 2 & 3 \\
1 & 3 & 3 & 2 \\
\end{bmatrix}
\cdot
\begin{bmatrix}
v_1 \\
v_2 \\
v_3 \\
v_4 \\
\end{bmatrix}
=
\begin{bmatrix}
0 \\
0 \\
\end{bmatrix}
\]

I will now put the matrix in rref because this will not change the null space. First subtract R1 from R2.
\[
\begin{bmatrix}
1 & 2 & 2 & 3 \\
0 & 1 & 1 & -1 \\
\end{bmatrix}
\cdot
\begin{bmatrix}
v_1 \\
v_2 \\
v_3 \\
v_4 \\
\end{bmatrix}
=
\begin{bmatrix}
0 \\
0 \\
\end{bmatrix}
\]
Finnaly subtract 2 R2 from R1.
\[
\begin{bmatrix}
1 & 0 & 0 & 5 \\
0 & 1 & 1 & -1 \\
\end{bmatrix}
\cdot
\begin{bmatrix}
v_1 \\
v_2 \\
v_3 \\
v_4 \\
\end{bmatrix}
=
\begin{bmatrix}
0 \\
0 \\
\end{bmatrix}
\]
Although $v$ will not the be same vector, it will still span the same space.
\[
\begin{bmatrix}
1 & 0 & 0 & 5 \\
0 & 1 & 1 & -1 \\
\end{bmatrix}
\cdot
\begin{bmatrix}
5 \\
-1 \\
0 \\
1 \\
\end{bmatrix}
=
\begin{bmatrix}
0 \\
0 \\
\end{bmatrix}
\]
\[
\begin{bmatrix}
1 & 0 & 0 & 5 \\
0 & 1 & 1 & -1 \\
\end{bmatrix}
\cdot
\begin{bmatrix}
0 \\
-1 \\
1 \\
0 \\
\end{bmatrix}
=
\begin{bmatrix}
0 \\
0 \\
\end{bmatrix}
\]
These are my two solutions to $rref(A)x = 0$. Now I can use them to form $S^{\perp}$
\[
\begin{bmatrix}
0 \\
-1 \\
1 \\
0 \\
\end{bmatrix}
\begin{bmatrix}
5 \\
-1 \\
0 \\
1 \\
\end{bmatrix}
\]
\section{Problem}
From what is given about $P$. The following equation must be true
\[
\begin{bmatrix}
1 & 1 & 1 & 1 \\
\end{bmatrix}
\cdot
\begin{bmatrix}
x_1 \\
x_2 \\
x_3 \\
x_4 \\
\end{bmatrix}
=
\begin{bmatrix}
0 \\
\end{bmatrix}
\]

Also I know the relation $P^{\perp} = N(P^{T})$. Given both of these facts I can generate:
\[
\begin{bmatrix}
x_1 & x_2 & x_3 & x_4 \\
\end{bmatrix}
\cdot
\begin{bmatrix}
1 \\
1 \\
1 \\
1 \\
\end{bmatrix}
=
\begin{bmatrix}
0 \\
\end{bmatrix}
\]
Therefore I can set the bases fro $P^{\perp}$ to be 
\[
\begin{bmatrix}
1 \\
1 \\
1 \\
1 \\
\end{bmatrix}
\]
\end{document}

